{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "#from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor\n",
    "#from django.db import transaction\n",
    "#from mlapp.models import Forecast, Correlation, Feature\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "devId = 'sm-0004'\n",
    "\n",
    "url_dev = f\"http://85.14.6.37:16455/api/posts/?date_range=year&not_res=true&dev={devId}\"\n",
    "url_weather = f\"http://85.14.6.37:16456/api/weather/?date_range=year&lat=43.2470&long=27.9291\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 timestamp           id  temperature  clouds  heatindex  \\\n",
      "0      2024-06-26 20:00:00     1.000000    20.700000    4.00  20.700000   \n",
      "1      2024-06-26 20:01:00     1.016667    20.686667    4.05  20.686667   \n",
      "2      2024-06-26 20:02:00     1.033333    20.673333    4.10  20.673333   \n",
      "3      2024-06-26 20:03:00     1.050000    20.660000    4.15  20.660000   \n",
      "4      2024-06-26 20:04:00     1.066667    20.646667    4.20  20.646667   \n",
      "...                    ...          ...          ...     ...        ...   \n",
      "183896 2024-11-01 12:56:00  2723.933333    17.073333    9.00  17.073333   \n",
      "183897 2024-11-01 12:57:00  2723.950000    17.080000    9.00  17.080000   \n",
      "183898 2024-11-01 12:58:00  2723.966667    17.086667    9.00  17.086667   \n",
      "183899 2024-11-01 12:59:00  2723.983333    17.093333    9.00  17.093333   \n",
      "183900 2024-11-01 13:00:00  2724.000000    17.100000    9.00  17.100000   \n",
      "\n",
      "              uv      lat     long  \n",
      "0       6.000000  43.2265  27.9504  \n",
      "1       5.916667  43.2265  27.9504  \n",
      "2       5.833333  43.2265  27.9504  \n",
      "3       5.750000  43.2265  27.9504  \n",
      "4       5.666667  43.2265  27.9504  \n",
      "...          ...      ...      ...  \n",
      "183896  5.000000  43.2265  27.9504  \n",
      "183897  5.000000  43.2265  27.9504  \n",
      "183898  5.000000  43.2265  27.9504  \n",
      "183899  5.000000  43.2265  27.9504  \n",
      "183900  5.000000  43.2265  27.9504  \n",
      "\n",
      "[183901 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(url_weather).json()\n",
    "dfWeather = None\n",
    "if response:\n",
    "    dfWeather = pd.DataFrame(response)\n",
    "    # Convert the 'created_date' column to datetime\n",
    "    dfWeather['timestamp'] = pd.to_datetime(dfWeather['timestamp'], errors='coerce')\n",
    "    dfWeather = dfWeather[~dfWeather['timestamp'].duplicated(keep='first')]\n",
    "    dfWeather.dropna(subset=['timestamp'], inplace=True)\n",
    "    dfWeather.set_index('timestamp', inplace=True)\n",
    "    dfWeather = dfWeather.resample('min').interpolate(method='linear')\n",
    "    dfWeather.reset_index(inplace=True)\n",
    "    dfWeather['timestamp'] = dfWeather[\"timestamp\"].values.astype('datetime64[m]')\n",
    "\n",
    "    print(dfWeather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'created_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Georgi\\pandas_django\\django_pandas_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'created_date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m df_sm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(response)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Convert the 'created_date' column to datetime\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df_sm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf_sm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_field_name\u001b[49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#Ensure that 'timestamp' column is in datetime64 format\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df_sm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_sm[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[m]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Georgi\\pandas_django\\django_pandas_venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Georgi\\pandas_django\\django_pandas_venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'created_date'"
     ]
    }
   ],
   "source": [
    "response = requests.get(url_dev).json()\n",
    "df_sm = None\n",
    "date_field_name = \"created\"\n",
    "if response:\n",
    "    df_sm = pd.DataFrame(response)\n",
    "    \n",
    "    #Convert the 'created_date' column to datetime\n",
    "    df_sm['timestamp'] = pd.to_datetime(df_sm[date_field_name], errors='coerce')\n",
    "    \n",
    "    #Ensure that 'timestamp' column is in datetime64 format\n",
    "    df_sm['timestamp'] = df_sm[\"timestamp\"].values.astype('datetime64[m]')\n",
    "    \n",
    "    df_sm = df_sm[~df_sm['timestamp'].duplicated(keep='first')]\n",
    "\n",
    "    # Drop rows where 'timestamp' could not be converted\n",
    "    df_sm.dropna(subset=['timestamp'], inplace=True)\n",
    "\n",
    "    # \n",
    "\n",
    "    # Set the timestamp as the index\n",
    "    df_sm.set_index('timestamp', inplace=True)\n",
    "    \n",
    "    # Resample to minute frequency, filling any gaps\n",
    "    \n",
    "    df_sm = df_sm.resample('min').interpolate(method='linear')\n",
    "    df_sm = df_sm.round(2)\n",
    "    df_sm['devId'] = devId\n",
    "    # Reset index to make timestamp a column again\n",
    "    df_sm.reset_index(inplace=True)        \n",
    "\n",
    "    columns_to_drop = [date_field_name, 'grid', 'actualCorr', 'actualProviding', 'providingAmount']\n",
    "    df_sm.drop(columns=columns_to_drop, inplace=True, errors='ignore') \n",
    "\n",
    "    print(df_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              timestamp    devId  value           id  temperature     clouds  \\\n",
      "0   2024-11-01 01:00:00  sm-0004  91.00  2712.000000    12.200000  24.000000   \n",
      "1   2024-11-01 01:01:00  sm-0004  96.00  2712.016667    12.198333  23.983333   \n",
      "2   2024-11-01 01:02:00  sm-0004  94.00  2712.033333    12.196667  23.966667   \n",
      "3   2024-11-01 01:03:00  sm-0004  88.00  2712.050000    12.195000  23.950000   \n",
      "4   2024-11-01 01:04:00  sm-0004  92.00  2712.066667    12.193333  23.933333   \n",
      "..                  ...      ...    ...          ...          ...        ...   \n",
      "716 2024-11-01 12:56:00  sm-0004  62.24  2723.933333    17.073333   9.000000   \n",
      "717 2024-11-01 12:57:00  sm-0004  62.47  2723.950000    17.080000   9.000000   \n",
      "718 2024-11-01 12:58:00  sm-0004  62.71  2723.966667    17.086667   9.000000   \n",
      "719 2024-11-01 12:59:00  sm-0004  62.94  2723.983333    17.093333   9.000000   \n",
      "720 2024-11-01 13:00:00  sm-0004  63.18  2724.000000    17.100000   9.000000   \n",
      "\n",
      "     heatindex   uv      lat     long  \n",
      "0    12.200000  0.0  43.2265  27.9504  \n",
      "1    12.198333  0.0  43.2265  27.9504  \n",
      "2    12.196667  0.0  43.2265  27.9504  \n",
      "3    12.195000  0.0  43.2265  27.9504  \n",
      "4    12.193333  0.0  43.2265  27.9504  \n",
      "..         ...  ...      ...      ...  \n",
      "716  17.073333  5.0  43.2265  27.9504  \n",
      "717  17.080000  5.0  43.2265  27.9504  \n",
      "718  17.086667  5.0  43.2265  27.9504  \n",
      "719  17.093333  5.0  43.2265  27.9504  \n",
      "720  17.100000  5.0  43.2265  27.9504  \n",
      "\n",
      "[721 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merged_df = None\n",
    "\n",
    "if dfWeather is not None and not dfWeather.empty and df_sm is not None and not df_sm.empty:\n",
    "    common_start_timestamp = max(df_sm['timestamp'].min(), dfWeather['timestamp'].min())\n",
    "    common_end_timestamp = min(df_sm['timestamp'].max(), dfWeather['timestamp'].max())\n",
    "    # Trim both DataFrames to start from the common start timestamp and end at the common end timestamp\n",
    "    power_processed_df_trimmed = df_sm[(df_sm['timestamp'] >= common_start_timestamp) & (df_sm['timestamp'] <= common_end_timestamp)].reset_index(drop=True)\n",
    "    weather_processed_df_trimmed = dfWeather[(dfWeather['timestamp'] >= common_start_timestamp) & (dfWeather['timestamp'] <= common_end_timestamp)].reset_index(drop=True)\n",
    "\n",
    "    merged_df = pd.merge(power_processed_df_trimmed, weather_processed_df_trimmed, on='timestamp', how='inner') \n",
    "\n",
    "    print(merged_df)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = merged_df\n",
    "if data is not None and not data.empty:\n",
    "    train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "        data,\n",
    "        id_column=\"devId\",\n",
    "        timestamp_column=\"timestamp\"\n",
    "    )\n",
    "    predictor = TimeSeriesPredictor(\n",
    "    prediction_length=700,\n",
    "    path=\"/autogluon\",  # Adjust path as needed\n",
    "    target=\"value\",\n",
    "    eval_metric=\"MASE\",\n",
    "    freq='T'  # Specify minute frequency\n",
    "    )\n",
    "    predictor.fit(\n",
    "    train_data,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=50,\n",
    "    )\n",
    "    predictions = predictor.predict(train_data)\n",
    "\n",
    "    for index, row in predictions.iterrows():            \n",
    "        timestamp = index[1]                \n",
    "        mean_value = round(row['mean'], 2)            \n",
    "        print(f\"Timestamp:{timestamp} || PredictedValue: {mean_value}\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "django_pandas_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
